{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uiyht_AB9Ne",
        "outputId": "4c7e6817-8697-49a9-dbd1-53dc4325e196"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LQ5l93FsBsS-"
      },
      "outputs": [],
      "source": [
        "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig\n",
        "from datasets import load_dataset\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Tc-yDbwwB4mz"
      },
      "outputs": [],
      "source": [
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased-finetuned-sst-2-english')\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased-finetuned-sst-2-english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5bdizXZCJh6",
        "outputId": "792810fd-3e7a-46a8-fd3f-dfc799768884"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DistilBertForSequenceClassification(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MPaBkqnUCLqx"
      },
      "outputs": [],
      "source": [
        "# Using the validation dataset to compare the two models performance\n",
        "dataset = load_dataset(\"glue\", \"sst2\", split=\"validation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NqXWj-tiCOyl"
      },
      "outputs": [],
      "source": [
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"sentence\"], padding=\"max_length\", truncation=True, max_length=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Gqrk7gJTGuuy"
      },
      "outputs": [],
      "source": [
        "def get_model_size(path):\n",
        "    total_size = 0\n",
        "    for dirpath, dirnames, filenames in os.walk(path):\n",
        "        for f in filenames:\n",
        "            fp = os.path.join(dirpath, f)\n",
        "            total_size += os.path.getsize(fp)\n",
        "    return total_size\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sqtW3YYGCbS1"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, dataset, num_samples=260):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Take a subset for evaluation\n",
        "        subset = dataset.select(range(num_samples))\n",
        "        inputs = torch.tensor(subset['input_ids'])\n",
        "        labels = torch.tensor(subset['label'])\n",
        "        attention_masks = torch.tensor(subset['attention_mask'])\n",
        "\n",
        "        outputs = model(inputs, attention_mask=attention_masks)\n",
        "        predictions = torch.argmax(outputs.logits, dim=1)\n",
        "        accuracy = accuracy_score(labels, predictions)\n",
        "        return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "g1tUuLILCT2o"
      },
      "outputs": [],
      "source": [
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KLe99p52CV4X"
      },
      "outputs": [],
      "source": [
        "# Using pytorch quantization to quantize the model to int8\n",
        "quantized_model = torch.quantization.quantize_dynamic(model, {torch.nn.Linear}, dtype=torch.qint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "949a9PqPR5rd",
        "outputId": "eb6a34da-d52c-4249-a2c3-20f3731145be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Model Accuracy: 0.9153846153846154\n"
          ]
        }
      ],
      "source": [
        "# Evaluate original model\n",
        "original_accuracy = evaluate_model(model, tokenized_dataset)\n",
        "print(f\"Original Model Accuracy: {original_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQIRcU3nR5gk",
        "outputId": "466aa011-c921-460d-a206-7c870f2b3ae5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quantized Model Accuracy: 0.9115384615384615\n"
          ]
        }
      ],
      "source": [
        "# Evaluate quantized model\n",
        "quantized_accuracy = evaluate_model(quantized_model, tokenized_dataset)\n",
        "print(f\"Quantized Model Accuracy: {quantized_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wZOyeRjOGKgo"
      },
      "outputs": [],
      "source": [
        "# Save the configuration\n",
        "quantized_model_path = \"/content/distilbert-quantized\"\n",
        "model_config = DistilBertConfig.from_pretrained('distilbert-base-uncased-finetuned-sst-2-english')\n",
        "model_config.save_pretrained(quantized_model_path)\n",
        "\n",
        "# Save the tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased-finetuned-sst-2-english')\n",
        "tokenizer.save_pretrained(quantized_model_path)\n",
        "\n",
        "# Save the model\n",
        "torch.save(quantized_model.state_dict(), f\"{quantized_model_path}/pytorch_model.bin\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cN9jjyliGNmU",
        "outputId": "21e5b603-c6da-4e9a-d989-2454145ab076"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:355: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  device=storage.device,\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the configuration and tokenizer\n",
        "config = DistilBertConfig.from_pretrained(quantized_model_path)\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(quantized_model_path)\n",
        "\n",
        "# Re-create the original model\n",
        "model = DistilBertForSequenceClassification(config)\n",
        "\n",
        "# Apply dynamic quantization (if the model was dynamically quantized)\n",
        "quantized_model = torch.quantization.quantize_dynamic(model, {torch.nn.Linear}, dtype=torch.qint8)\n",
        "\n",
        "# Load the saved state dictionary\n",
        "quantized_model.load_state_dict(torch.load(f\"{quantized_model_path}/pytorch_model.bin\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "PEsKPDQ8GRl5"
      },
      "outputs": [],
      "source": [
        "# Saving the original model for comparison\n",
        "original_model_path = \"/content/distilbert-original\"\n",
        "model.save_pretrained(original_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WzWtJxlrGudL"
      },
      "outputs": [],
      "source": [
        "# Get the size of the original and quantized models\n",
        "original_size = get_model_size(original_model_path) / (1024 * 1024)  # Convert to MB\n",
        "quantized_size = get_model_size(quantized_model_path) / (1024 * 1024)  # Convert to MB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxRohi9LP1jy",
        "outputId": "c3cb07d2-d469-43e3-c4a7-f32c2a33bd75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Model Size: 255.43 MB\n",
            "Original Model Accuracy: 0.9153846153846154\n",
            "Quantized Model Size: 132.51 MB\n",
            "Quantized Model Accuracy: 0.9115384615384615\n"
          ]
        }
      ],
      "source": [
        "# Evaluate original and quantized models\n",
        "print(f\"Original Model Size: {original_size:.2f} MB\")\n",
        "print(f\"Original Model Accuracy: {original_accuracy}\")\n",
        "print(f\"Quantized Model Size: {quantized_size:.2f} MB\")\n",
        "print(f\"Quantized Model Accuracy: {quantized_accuracy}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
